{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Word embeddings\n",
        "import numpy as np\n",
        "embeddings_index = {}\n",
        "f = open('') #GloVe word embeddings\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "id": "P3FoK73yS12y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, max_length_emb))\n",
        "print(embedding_matrix.shape)\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "bBkhA4GRTKZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmDjodEkSfTN"
      },
      "outputs": [],
      "source": [
        "def training5(X_test,X_test_emo, X_train,X_train_emo, y_train, X_val,X_val_emo,y_val, epocas=7):\n",
        "  nlp_input = Input(shape=(max_length,), name='nlp_input')\n",
        "  meta_input=Input(shape=(4,))\n",
        "  emb_1 = Embedding(len(word_index)+1, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)(nlp_input)\n",
        "  y=Conv1D(250, (3), kernel_regularizer=regularizers.l2(l2=1e-4),bias_regularizer=regularizers.l2(1e-4),activation='relu')(emb_1)\n",
        "  y=GlobalMaxPooling1D()(y)\n",
        "  conc = concatenate([y, meta_input])\n",
        "  y=Dense(254, kernel_regularizer=regularizers.l2(l2=1e-4),bias_regularizer=regularizers.l2(1e-4), activation='relu')(conc) #128\n",
        "  output = Dense(1,kernel_regularizer=regularizers.l2(l2=1e-4),bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-4), activation='sigmoid')(y)\n",
        "  model = Model(inputs=[nlp_input,meta_input], outputs=[output])\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.007)\n",
        "  model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "  model.fit(x=[X_train,X_train_emo],y=y_train, epochs=epocas, validation_data=([X_val,X_val_emo],y_val),batch_size = 32, verbose = 1)\n",
        "  y_pred=model.predict([X_test,X_test_emo])\n",
        "  y_pred=np.around(y_pred)\n",
        "  y_pred=y_pred.astype(int)\n",
        "  return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def kParticiones_KM3(particiones,X,X_emo,y, epocas=10):\n",
        "    metricas_k=pd.DataFrame(columns=['accuracy', 'precision', 'recall','f1-score'], index=(range(1,particiones+1)))\n",
        "    #kf = KFold(n_splits=particiones, shuffle=True)\n",
        "    kf = StratifiedKFold(n_splits=particiones)\n",
        "    p = [];  r = []; a = []; funo = []; area=[]\n",
        "    for train_index, test_index in kf.split(X,y):# K-PARTICIONES\n",
        "        X_train=X[train_index] #\n",
        "        X_train_emo=X_emo[train_index]\n",
        "        test_x=X[test_index]\n",
        "        test_x_emo=X_emo[test_index]\n",
        "        y_train=y[train_index]\n",
        "        test_y=y[test_index]\n",
        "        X_test, X_val,X_test_emo, X_val_emo, y_test, y_val = train_test_split(test_x,test_x_emo, test_y, test_size=0.5)\n",
        "        y_pred=training5(X_test,X_test_emo,X_train,X_train_emo, y_train,X_val,X_val_emo, y_val, epocas=epocas)\n",
        "        pr,rec,acc,f1 = testing(y_pred, y_test) #Test the model\n",
        "        p.append(pr) #Metrics\n",
        "        r.append(rec)\n",
        "        a.append(acc)\n",
        "        funo.append(f1)\n",
        "        m = tf.keras.metrics.AUC()#num_thresholds=3\n",
        "        m.update_state(y_test, y_pred)\n",
        "        ar=m.result().numpy()\n",
        "        area.append(ar)\n",
        "        m.reset_state()\n",
        "    metricas_k['accuracy']=a; metricas_k['precision']=p;metricas_k['recall']=r;metricas_k['f1-score']=funo;\n",
        "    precision=np.mean(p) #Metrics after validation\n",
        "    recall=np.mean(r)\n",
        "    accuracy=np.mean(a)\n",
        "    f1_score=np.mean(funo)\n",
        "    area_curva=np.mean(area)\n",
        "    return precision,recall,accuracy,f1_score,area_curva,metricas_k"
      ],
      "metadata": {
        "id": "3ta31tQlTTpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}